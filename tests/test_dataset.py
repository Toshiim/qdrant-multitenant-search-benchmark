"""Tests for dataset module."""

import numpy as np
import pytest

from benchmark.config import Config
from benchmark.dataset import (
    Dataset,
    HF_AVAILABLE,
    HF_DATASET_INFO,
    assign_categories,
    batch_vectors,
    generate_synthetic_dataset,
    get_vectors_by_category,
    load_huggingface_dataset,
)


class TestGenerateSyntheticDataset:
    """Tests for synthetic dataset generation."""

    def test_basic_generation(self):
        """Test basic synthetic dataset generation."""
        dataset = generate_synthetic_dataset(
            num_vectors=1000,
            dimensions=64,
            num_queries=100,
            distance="Cosine",
        )
        
        assert dataset.name == "synthetic-1000-64"
        assert dataset.vectors.shape == (1000, 64)
        assert dataset.queries.shape == (100, 64)
        assert dataset.dimensions == 64
        assert dataset.distance == "Cosine"

    def test_cosine_no_prenormalization(self):
        """Test vectors are NOT normalized for cosine distance.
        
        Qdrant automatically normalizes vectors internally when using
        Cosine distance, so pre-normalization is redundant.
        """
        dataset = generate_synthetic_dataset(
            num_vectors=100,
            dimensions=32,
            distance="Cosine",
        )
        
        # Check that vectors are NOT pre-normalized (L2 norm varies)
        norms = np.linalg.norm(dataset.vectors, axis=1)
        # Not all vectors should have norm of 1 (they're random)
        assert not np.allclose(norms, np.ones(100))
        # Verify norms have meaningful variance (random vectors)
        assert norms.std() > 0.1, "Vector norms should vary significantly"

    def test_euclidean_not_normalized(self):
        """Test vectors are not normalized for euclidean distance."""
        dataset = generate_synthetic_dataset(
            num_vectors=100,
            dimensions=32,
            distance="Euclidean",
        )
        
        # Vectors should NOT all be normalized
        norms = np.linalg.norm(dataset.vectors, axis=1)
        assert not np.allclose(norms, np.ones(100))

    def test_reproducibility(self):
        """Test seed produces reproducible results."""
        dataset1 = generate_synthetic_dataset(
            num_vectors=100,
            dimensions=32,
            seed=42,
        )
        dataset2 = generate_synthetic_dataset(
            num_vectors=100,
            dimensions=32,
            seed=42,
        )
        
        np.testing.assert_array_equal(dataset1.vectors, dataset2.vectors)


class TestAssignCategories:
    """Tests for category assignment."""

    def test_uniform_distribution(self):
        """Test uniform category distribution."""
        categories = assign_categories(
            num_vectors=10000,
            num_categories=10,
            distribution="uniform",
        )
        
        assert len(categories) == 10000
        assert categories.min() >= 0
        assert categories.max() < 10
        
        # Check roughly uniform distribution
        counts = np.bincount(categories)
        assert len(counts) == 10
        # Each category should have roughly 1000 vectors (Â±20%)
        for count in counts:
            assert 800 < count < 1200

    def test_zipfian_distribution(self):
        """Test zipfian category distribution."""
        categories = assign_categories(
            num_vectors=10000,
            num_categories=10,
            distribution="zipfian",
        )
        
        assert len(categories) == 10000
        assert categories.min() >= 0
        assert categories.max() < 10
        
        # Check that distribution is skewed (first categories have more)
        counts = np.bincount(categories, minlength=10)
        assert counts[0] > counts[-1]

    def test_reproducibility(self):
        """Test seed produces reproducible results."""
        cat1 = assign_categories(1000, 10, seed=42)
        cat2 = assign_categories(1000, 10, seed=42)
        
        np.testing.assert_array_equal(cat1, cat2)


class TestBatchVectors:
    """Tests for vector batching."""

    def test_basic_batching(self):
        """Test basic batch generation."""
        vectors = np.random.randn(100, 32).astype(np.float32)
        categories = np.random.randint(0, 5, size=100)
        
        batches = list(batch_vectors(vectors, categories, batch_size=25))
        
        assert len(batches) == 4  # 100 / 25 = 4 batches
        
        for batch_vecs, batch_ids, batch_cats in batches:
            assert len(batch_vecs) == 25
            assert len(batch_ids) == 25
            assert len(batch_cats) == 25

    def test_partial_last_batch(self):
        """Test handling of partial last batch."""
        vectors = np.random.randn(75, 32).astype(np.float32)
        categories = np.random.randint(0, 5, size=75)
        
        batches = list(batch_vectors(vectors, categories, batch_size=25))
        
        assert len(batches) == 3  # 75 / 25 = 3 batches
        
        # Check last batch is full
        assert len(batches[-1][0]) == 25


class TestGetVectorsByCategory:
    """Tests for category filtering."""

    def test_filter_by_category(self):
        """Test filtering vectors by category."""
        vectors = np.array([
            [1, 0],
            [2, 0],
            [3, 0],
            [4, 0],
            [5, 0],
        ], dtype=np.float32)
        categories = np.array([0, 1, 0, 1, 0])
        
        cat0_vectors, cat0_indices = get_vectors_by_category(vectors, categories, 0)
        
        assert len(cat0_vectors) == 3
        assert cat0_indices == [0, 2, 4]
        np.testing.assert_array_equal(
            cat0_vectors,
            np.array([[1, 0], [3, 0], [5, 0]], dtype=np.float32)
        )

    def test_empty_category(self):
        """Test filtering with no matches."""
        vectors = np.array([[1, 0], [2, 0]], dtype=np.float32)
        categories = np.array([0, 0])
        
        result_vectors, result_indices = get_vectors_by_category(vectors, categories, 5)
        
        assert len(result_vectors) == 0
        assert result_indices == []


class TestHuggingFaceDataset:
    """Tests for Hugging Face dataset loading."""

    def test_hf_available(self):
        """Test that Hugging Face datasets library is available."""
        assert HF_AVAILABLE, "datasets library should be available"

    def test_hf_dataset_info_exists(self):
        """Test that HF_DATASET_INFO is properly configured."""
        assert len(HF_DATASET_INFO) > 0
        assert "dbpedia-entities-openai-1M" in HF_DATASET_INFO
        
        # Verify structure
        info = HF_DATASET_INFO["dbpedia-entities-openai-1M"]
        assert "repo_id" in info
        assert "embedding_column" in info
        assert "dimensions" in info
        assert "distance" in info
        assert info["repo_id"] == "KShivendu/dbpedia-entities-openai-1M"

    @pytest.mark.skipif(not HF_AVAILABLE, reason="datasets library not available")
    def test_load_huggingface_function_exists(self):
        """Test that load_huggingface_dataset function is callable."""
        assert callable(load_huggingface_dataset)

    def test_hf_not_available_error(self):
        """Test error when datasets library is not available."""
        # This test verifies the error handling when HF is not available
        # Since HF_AVAILABLE is True in our environment, we skip this
        # But the function should raise ImportError when HF is not available
        pass
